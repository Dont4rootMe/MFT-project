{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68300fa",
   "metadata": {},
   "source": [
    "# Тестирование классической модели KNN для предсказания увеличения/уменьшения катировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import ArrayLike\n",
    "from scipy.fft import dct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aaf241",
   "metadata": {},
   "source": [
    "## Data proccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dt_path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(dt_path)[['open', 'high', 'low', 'close']]\n",
    "\n",
    "def preproccess_data(dts: pd.DataFrame, window_size: int) -> list[tuple[int, ArrayLike, ArrayLike, ArrayLike]]:\n",
    "    dataset = []\n",
    "    \n",
    "    close = dts['close'].array\n",
    "    open  = dts['open'].array\n",
    "    frame = (dts['close'] - dts['open']).array\n",
    "    for start in range(len(dts) - window_size - 1):\n",
    "        end   = start + window_size\n",
    "        body  = frame[start: end]\n",
    "        label = 2 * (frame[end] > 0) - 1\n",
    "        dataset.append((label, body, open[end], close[end]))\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def dct_composition(dataset: list, main_components: None | int) -> list[tuple[int, ArrayLike, ArrayLike, ArrayLike]]:\n",
    "    # if main_components is None => identity mapping\n",
    "    composition = dct if main_components is None else lambda x: dct(x)[:main_components]\n",
    "    return [\n",
    "        (label, composition(body), open, close) for label, body, open, close in dataset\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_fabric(\n",
    "    dts_path: str, \n",
    "    window_size: int, \n",
    "    dct_transform: bool = False, \n",
    "    main_components: int | None = None\n",
    ") -> list[tuple[int, ArrayLike]]:\n",
    "    dataset = preproccess_data(\n",
    "        load_data(dts_path),\n",
    "        window_size,\n",
    "    )\n",
    "    \n",
    "    if dct_transform:\n",
    "        return dct_composition(dataset, main_components)\n",
    "    else:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc9c81",
   "metadata": {},
   "source": [
    "## Metrics for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pyts.metrics import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b958bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metric(\n",
    "    metric_type: str,\n",
    "    distance_type: str = 'square',\n",
    "    dtw_method = 'classic',\n",
    "    dtw_options = None\n",
    "):\n",
    "    assert metric_type in ['DTW'], f'wrong metric_type={metric_type}'\n",
    "    assert distance_type in ['square', 'absolute']\n",
    "    \n",
    "    match metric_type:\n",
    "        case 'DTW':\n",
    "            return partial(dtw, dist=distance_type, method=dtw_method, options=dtw_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386241d5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyClassifier: \n",
    "    def __init__(self, metric, k_neighbours = 1, weighted = True): \n",
    "        # settings of model\n",
    "        self.metric       = metric\n",
    "        self.k_neighbours = k_neighbours\n",
    "        self.weighted     = weighted\n",
    "        \n",
    "        # model's memory\n",
    "        self.neighbours   = []\n",
    "        \n",
    "    def add_object(self, label, x):\n",
    "        self.neighbours.append((label, x))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        scores = []\n",
    "        labels = []\n",
    "        for label, neighbour in self.neighbours:\n",
    "            labels.append(label)\n",
    "            scores.append(self.metric(x, neighbour))\n",
    "            \n",
    "        scores     = np.array(scores)\n",
    "        labels     = np.array(labels)\n",
    "        best_match = np.argpartition(-scores, self.k_neighbours)[:self.k_neighbours]\n",
    "        \n",
    "        if self.weighted:\n",
    "            weights = softmax(1 / scores[best_match])\n",
    "            return 2 * (labels[best_match] @ weights > 0) - 1\n",
    "        else:\n",
    "            return 2 * (labels[best_match].mean() > 0) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eaaa98",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model, \n",
    "    dataset: list, \n",
    "    warm_start: int = 30\n",
    "):  \n",
    "    # Validate dataset length\n",
    "    if len(dataset) <= warm_start:\n",
    "        raise ValueError(f\"Dataset size ({len(dataset)}) must exceed warm_start ({warm_start})\")\n",
    "    \n",
    "    # Warm up model\n",
    "    for i in range(warm_start):\n",
    "        label, body, _, _ = dataset[i]\n",
    "        model.add_object(label, body)\n",
    "    \n",
    "    # Initialize trading\n",
    "    initial_price = dataset[warm_start][2]  # Open price\n",
    "    initial_bank = 10 * initial_price\n",
    "    current_bank = initial_bank\n",
    "    current_currency = 0\n",
    "    in_position = False\n",
    "    \n",
    "    real_labels = []\n",
    "    predicted_labels = []  # Will store binary predictions (1/-1)\n",
    "    \n",
    "    # Trading simulation\n",
    "    for i in range(warm_start, len(dataset)):\n",
    "        label, body, open_price, close_price = dataset[i]\n",
    "        \n",
    "        # Get prediction and classify\n",
    "        raw_pred = model(body)\n",
    "        pred_class = 1 if raw_pred > 0 else -1  # Binarize prediction\n",
    "        \n",
    "        real_labels.append(label)\n",
    "        predicted_labels.append(pred_class)\n",
    "        \n",
    "        # Trading rules - use explicit conditions\n",
    "        if pred_class > 0 and not in_position:\n",
    "            # Buy at open\n",
    "            current_currency = current_bank / open_price\n",
    "            current_bank = 0\n",
    "            in_position = True\n",
    "            \n",
    "        elif pred_class < 0 and in_position:\n",
    "            # Sell at close\n",
    "            current_bank = current_currency * open_price\n",
    "            current_currency = 0\n",
    "            in_position = False\n",
    "    \n",
    "    # Close final position\n",
    "    if in_position:\n",
    "        _, _, _, final_close = dataset[-1]\n",
    "        current_bank = current_currency * final_close\n",
    "    \n",
    "    # Calculate metrics\n",
    "    real_labels = np.array(real_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    \n",
    "    # Ensure labels are binary (1/-1)\n",
    "    if not np.array_equal(np.unique(real_labels), [-1, 1]):\n",
    "        real_labels = np.where(real_labels > 0, 1, -1)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(real_labels, predicted_labels),\n",
    "        'precision': precision_score(real_labels, predicted_labels, pos_label=1),\n",
    "        'recall': recall_score(real_labels, predicted_labels, pos_label=1),\n",
    "        'f1_score': f1_score(real_labels, predicted_labels, pos_label=1),\n",
    "        'return_multiplier': current_bank / initial_bank\n",
    "    }\n",
    "    \n",
    "    return current_bank, current_bank / initial_bank, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99c904",
   "metadata": {},
   "source": [
    "## Optuna tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(trial: optuna.trial.Trial):\n",
    "    k_neighbours = trial.suggest_categorical(\"k_neighbours\", range(1, 10))\n",
    "    weighted = trial.suggest_categorical(\"KNN_weighted\", [True, False])\n",
    "    distance_type = trial.suggest_categorical('distance_type', ['square', 'absolute'])\n",
    "    \n",
    "    window_size = trial.suggest_categorical('window_len', range(5, 21))\n",
    "    transform_dct = trial.suggest_categorical('dct_transform', [True, False])\n",
    "    main_components = trial.suggest_categorical('main_components', [None, 0.5, 0.7])\n",
    "    \n",
    "    if main_components is not None:\n",
    "        components = int(window_size * main_components)\n",
    "    else:\n",
    "        components = None\n",
    "    \n",
    "    metric = create_metric('DTW', distance_type)\n",
    "    model = DummyClassifier(metric=metric, k_neighbours=k_neighbours, weighted=weighted)\n",
    "    dataset = dataset_fabric('../data/TONUSDT.csv', window_size, transform_dct, components)\n",
    "    \n",
    "    current_bank, ratio, metrics = validate(model, dataset, 30)\n",
    "    \n",
    "    # trial.set_user_attr(\"metrics\", metrics)\n",
    "    return ratio\n",
    "\n",
    "try:\n",
    "    sampler = optuna.samplers.TPESampler(n_startup_trials=10, group=True, multivariate=True)\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        load_if_exists=True,\n",
    "        storage=\"sqlite:///../optuna/KNN_first_trial_db.sqlite3\",\n",
    "        direction=\"maximize\", \n",
    "        study_name=\"TON\")\n",
    "    study.optimize(trial, n_trials=300, n_jobs=15, show_progress_bar=True)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(trial: optuna.trial.Trial):\n",
    "    k_neighbours = trial.suggest_categorical(\"k_neighbours\", range(1, 10))\n",
    "    weighted = trial.suggest_categorical(\"KNN_weighted\", [True, False])\n",
    "    distance_type = trial.suggest_categorical('distance_type', ['square', 'absolute'])\n",
    "    \n",
    "    window_size = trial.suggest_categorical('window_len', range(5, 21))\n",
    "    transform_dct = trial.suggest_categorical('dct_transform', [True, False])\n",
    "    main_components = trial.suggest_categorical('main_components', [None, 0.5, 0.7])\n",
    "    \n",
    "    if main_components is not None:\n",
    "        components = int(window_size * main_components)\n",
    "    else:\n",
    "        components = None\n",
    "    \n",
    "    metric = create_metric('DTW', distance_type)\n",
    "    model = DummyClassifier(metric=metric, k_neighbours=k_neighbours, weighted=weighted)\n",
    "    dataset = dataset_fabric('../data/LINKUSDT.csv', window_size, transform_dct, components)\n",
    "    \n",
    "    current_bank, ratio, metrics = validate(model, dataset, 30)\n",
    "    \n",
    "    # trial.set_user_attr(\"metrics\", metrics)\n",
    "    return ratio\n",
    "\n",
    "try:\n",
    "    sampler = optuna.samplers.TPESampler(n_startup_trials=10, group=True, multivariate=True)\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        load_if_exists=True,\n",
    "        storage=\"sqlite:///../optuna/KNN_first_trial_db.sqlite3\",\n",
    "        direction=\"maximize\", \n",
    "        study_name=\"LINK\")\n",
    "    study.optimize(trial, n_trials=100, n_jobs=15, show_progress_bar=True)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4230eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(trial: optuna.trial.Trial):\n",
    "    k_neighbours = trial.suggest_categorical(\"k_neighbours\", range(1, 10))\n",
    "    weighted = trial.suggest_categorical(\"KNN_weighted\", [True, False])\n",
    "    distance_type = trial.suggest_categorical('distance_type', ['square', 'absolute'])\n",
    "    \n",
    "    window_size = trial.suggest_categorical('window_len', range(5, 21))\n",
    "    transform_dct = trial.suggest_categorical('dct_transform', [True, False])\n",
    "    main_components = trial.suggest_categorical('main_components', [None, 0.5, 0.7])\n",
    "    \n",
    "    if main_components is not None:\n",
    "        components = int(window_size * main_components)\n",
    "    else:\n",
    "        components = None\n",
    "    \n",
    "    metric = create_metric('DTW', distance_type)\n",
    "    model = DummyClassifier(metric=metric, k_neighbours=k_neighbours, weighted=weighted)\n",
    "    dataset = dataset_fabric('../data/XRPUSDT.csv', window_size, transform_dct, components)\n",
    "    \n",
    "    current_bank, ratio, metrics = validate(model, dataset, 30)\n",
    "    \n",
    "    # trial.set_user_attr(\"metrics\", metrics)\n",
    "    return ratio\n",
    "\n",
    "try:\n",
    "    sampler = optuna.samplers.TPESampler(n_startup_trials=10, group=True, multivariate=True)\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        load_if_exists=True,\n",
    "        storage=\"sqlite:///../optuna/KNN_first_trial_db.sqlite3\",\n",
    "        direction=\"maximize\", \n",
    "        study_name=\"XRP\")\n",
    "    study.optimize(trial, n_trials=100, n_jobs=15, show_progress_bar=True)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(trial: optuna.trial.Trial):\n",
    "    k_neighbours = trial.suggest_categorical(\"k_neighbours\", range(1, 10))\n",
    "    weighted = trial.suggest_categorical(\"KNN_weighted\", [True, False])\n",
    "    distance_type = trial.suggest_categorical('distance_type', ['square', 'absolute'])\n",
    "    \n",
    "    window_size = trial.suggest_categorical('window_len', range(5, 21))\n",
    "    transform_dct = trial.suggest_categorical('dct_transform', [True, False])\n",
    "    main_components = trial.suggest_categorical('main_components', [None, 0.5, 0.7])\n",
    "    \n",
    "    if main_components is not None:\n",
    "        components = int(window_size * main_components)\n",
    "    else:\n",
    "        components = None\n",
    "    \n",
    "    metric = create_metric('DTW', distance_type)\n",
    "    model = DummyClassifier(metric=metric, k_neighbours=k_neighbours, weighted=weighted)\n",
    "    dataset = dataset_fabric('../data/SOLUSDT.csv', window_size, transform_dct, components)\n",
    "    \n",
    "    current_bank, ratio, metrics = validate(model, dataset, 30)\n",
    "    \n",
    "    # trial.set_user_attr(\"metrics\", metrics)\n",
    "    return ratio\n",
    "\n",
    "try:\n",
    "    sampler = optuna.samplers.TPESampler(n_startup_trials=10, group=True, multivariate=True)\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        load_if_exists=True,\n",
    "        storage=\"sqlite:///../optuna/KNN_first_trial_db.sqlite3\",\n",
    "        direction=\"maximize\", \n",
    "        study_name=\"SOL\")\n",
    "    study.optimize(trial, n_trials=75, n_jobs=15, show_progress_bar=True)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(trial: optuna.trial.Trial):\n",
    "    k_neighbours = trial.suggest_categorical(\"k_neighbours\", range(1, 10))\n",
    "    weighted = trial.suggest_categorical(\"KNN_weighted\", [True, False])\n",
    "    distance_type = trial.suggest_categorical('distance_type', ['square', 'absolute'])\n",
    "    \n",
    "    window_size = trial.suggest_categorical('window_len', range(5, 21))\n",
    "    transform_dct = trial.suggest_categorical('dct_transform', [True, False])\n",
    "    main_components = trial.suggest_categorical('main_components', [None, 0.5, 0.7])\n",
    "    \n",
    "    if main_components is not None:\n",
    "        components = int(window_size * main_components)\n",
    "    else:\n",
    "        components = None\n",
    "    \n",
    "    metric = create_metric('DTW', distance_type)\n",
    "    model = DummyClassifier(metric=metric, k_neighbours=k_neighbours, weighted=weighted)\n",
    "    dataset = dataset_fabric('../data/PEPEUSDT.csv', window_size, transform_dct, components)\n",
    "    \n",
    "    current_bank, ratio, metrics = validate(model, dataset, 30)\n",
    "    \n",
    "    # trial.set_user_attr(\"metrics\", metrics)\n",
    "    return ratio\n",
    "\n",
    "try:\n",
    "    sampler = optuna.samplers.TPESampler(n_startup_trials=10, group=True, multivariate=True)\n",
    "    study = optuna.create_study(\n",
    "        sampler=sampler,\n",
    "        load_if_exists=True,\n",
    "        storage=\"sqlite:///../optuna/KNN_first_trial_db.sqlite3\",\n",
    "        direction=\"maximize\", \n",
    "        study_name=\"PEPE\")\n",
    "    study.optimize(trial, n_trials=75, n_jobs=15, show_progress_bar=True)\n",
    "except: pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MFT-project-lheyyFxX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
